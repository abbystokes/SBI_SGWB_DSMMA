{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab as plt\n",
    "import torch\n",
    "import scipy.stats as stats\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl\n",
    "import swyft\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, Dataset, DataLoader\n",
    "\n",
    "\n",
    "\n",
    "DEVICE = 'gpu' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Define simulator parameters\n",
    "f_low = 10\n",
    "f_high = 1024\n",
    "N_bins = 4076\n",
    "freq = np.linspace(f_low, f_high, N_bins)\n",
    "pi = np.pi\n",
    "sqrt = np.sqrt\n",
    "H100 = 3.241e-18\n",
    "h    = 0.679\n",
    "H0   = h * H100\n",
    "\n",
    "# Define Simulator\n",
    "class Simulator(swyft.Simulator):\n",
    "    def __init__(self, fref, psd, gamma, T_obs, Nbins=len(freq), bounds=None):\n",
    "        super().__init__()\n",
    "        self.fref      = fref\n",
    "        self.psd       = psd\n",
    "        self.gamma     = gamma\n",
    "        self.T_obs     = T_obs\n",
    "        \n",
    "        self.transform_samples = swyft.to_numpy32\n",
    "        self.Nbins = Nbins\n",
    "        self.freq = np.linspace(f_low, f_high, N_bins)\n",
    "        self.sample_z = swyft.RectBoundSampler([stats.uniform(-9,2), #omega\n",
    "                                                stats.uniform(0,3)], #alpha\n",
    "                                                bounds = bounds) #bounds changes range of the prior\n",
    "\n",
    "    def psd_interp(self):\n",
    "        return scipy.interpolate.interp1d(self.psd[:,0], self.psd[:,1])(self.freq)\n",
    "    \n",
    "    def gamma_interp(self):\n",
    "        return scipy.interpolate.interp1d(self.gamma[:, 0], self.gamma[:, 1])(self.freq)\n",
    "    \n",
    "    def sigma(self):\n",
    "        numerator = (20*pi**2*self.freq**3)**2 * self.psd_interp()**2\n",
    "        denomenator = (3*H0**2)**2 * 8*self.gamma_interp()**2\n",
    "        T = 1/(self.freq[1]-self.freq[0])\n",
    "        N = 2*self.T_obs // T - 1\n",
    "        return np.sqrt(numerator/denomenator/N)\n",
    "    \n",
    "    def C_groundtruth(self, z):\n",
    "        Omega_ref = 10**z[0]\n",
    "        alpha     = z[1]\n",
    "        C_hat_ij = Omega_ref * (self.freq/self.fref)**alpha\n",
    "        return C_hat_ij\n",
    "    \n",
    "    def build(self, graph):\n",
    "        z = graph.node('z', self.sample_z)\n",
    "        m = graph.node('m', self.C_groundtruth, z)\n",
    "        x = graph.node(\"x\", lambda m: m + np.random.normal(0, self.sigma()), m)\n",
    "        #x = graph.node(\"x\", lambda m: m + 0, m) #Ground truth wih sigma noise\n",
    "        sigma = graph.node('sigma',self.sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c26c4fe85873410e9bcfbad749ce3e6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sample from Simulator\n",
    "\n",
    "n_samples = 10000\n",
    "fref = 25\n",
    "CE_PSD = np.genfromtxt(\"data/cosmic_explorer_40km_for_paper.txt\")\n",
    "CE_PSD[0, 0]  = 4.99999999999999999\n",
    "CE_PSD[:, 1] = CE_PSD[:, 1]**2\n",
    "gamma_HL = np.genfromtxt(\"data/gamma_HL.txt\")\n",
    "T_obs = 365 * 24 * 3600\n",
    "\n",
    "sim = Simulator(fref, CE_PSD, gamma_HL, T_obs, bounds=None)\n",
    "obs = sim.sample(conditions = {'z': np.array([5e-8, 2.1])})\n",
    "sims = sim.sample(N = n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "samples = swyft.Samples(x=np.log10(np.abs(sims['x'][1:])), z=sims['z'][1:]) # Samples for training network\n",
    "obs = swyft.Sample(x=np.log10(np.abs(sims['x'][0])), z=sims['z'][0] ) # Example observation for inference\n",
    "\n",
    "# Set aside observation parameters for later\n",
    "obs_omega = sims['z'][0][0]\n",
    "obs_alpha = sims['z'][0][1]\n",
    "\n",
    "# Plot example observation\n",
    "plt.semilogx(sim.freq, obs['x'], 'r', lw=2)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "\n",
    "# Define VAE\n",
    "\n",
    "class VAE(swyft.SwyftModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.summarizer = nn.Sequential(nn.Linear(4076, 1024),\n",
    "                                        nn.Linear(1024, 256),\n",
    "                                        nn.Linear(256, 64),\n",
    "                                        nn.Linear(64, 16)\n",
    "\n",
    "        )\n",
    "\n",
    "\n",
    "        # Encoder layers (same as before, but with mu and logvar layers)\n",
    "        #self.encoder_fc1 = nn.Linear(4076, 1024)\n",
    "        #self.encoder_fc2 = nn.Linear(1024, 256)\n",
    "        #self.encoder_fc3 = nn.Linear(256, 64)\n",
    "\n",
    "        # Latent space mean and log variance\n",
    "        #self.fc_mu = nn.Linear(64, 16)\n",
    "       # self.fc_logvar = nn.Linear(64, 16)\n",
    "\n",
    "\n",
    "        #self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "        self.logratios = swyft.LogRatioEstimator_1dim(\n",
    "            num_features=16,  # Number of features in compressed x (simulated observation)\n",
    "            num_params=2,    # Two parameters to infer: alpha and omega\n",
    "            varnames='z',  # Names of the parameters\n",
    "            num_blocks=4     # Number of neural network blocks\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, A, B): \n",
    "        s = self.summarizer(A['x'])\n",
    "        return self.logratios(s, B['z'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9999, 16])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer = nn.Sequential(nn.Linear(4076, 1024),\n",
    "                                        nn.Linear(1024, 256),\n",
    "                                        nn.Linear(256, 64),\n",
    "                                        nn.Linear(64, 16)\n",
    "\n",
    "        )\n",
    "np.shape(summarizer(torch.tensor(samples['x'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/lexington/anaconda3/envs/test_env/lib/python3.11/site-packages/pytorch_lightning/trainer/setup.py:201: UserWarning: MPS available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='mps', devices=1)`.\n",
      "  rank_zero_warn(\n",
      "/Users/lexington/anaconda3/envs/test_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "  warning_cache.warn(\n",
      "/Users/lexington/anaconda3/envs/test_env/lib/python3.11/site-packages/pytorch_lightning/loops/utilities.py:94: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "  rank_zero_warn(\n",
      "The following callbacks returned in `LightningModule.configure_callbacks` will override existing callbacks passed to Trainer: ModelCheckpoint\n",
      "\n",
      "  | Name       | Type                   | Params\n",
      "------------------------------------------------------\n",
      "0 | summarizer | Sequential             | 4.5 M \n",
      "1 | logratios  | LogRatioEstimator_1dim | 71.0 K\n",
      "------------------------------------------------------\n",
      "4.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.5 M     Total params\n",
      "36.206    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d9ecab3e1334fd4bc9fc3fa35e256c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lexington/anaconda3/envs/test_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/Users/lexington/anaconda3/envs/test_env/lib/python3.11/site-packages/torch/__init__.py:1144: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:434.)\n",
      "  _C._set_default_tensor_type(t)\n",
      "/Users/lexington/anaconda3/envs/test_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2e911a3e2194192add5829759410258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4c048ec67f741b4b9b19aa86b7f4c00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "910754996b3f4be5b315f0f87cfa77b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3506cdb4d60422b90c66db01968fd60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70279ee7e34141dba916199f5cba80f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "315b66a685c945278849f6735cef7f0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bced557200574e188765c5b1033ac8c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "852771c055254c6483510942dd353c30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f19bf257b4449dfb4bf262140958ff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7468285ed6044ecadbf5a61b6bd44ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81bad08109a54cad8e6fe9f1f9be9b0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "180889ec382b4e26962c5ea3ea85d919",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "936212d3da334974ad9a3a0530b81c79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e93217c438c041d6a8decc302af89efa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7339fb58f6b47a2946bd5c1789ca5e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading best model: /Users/lexington/Documents/GitHub/SBI_SGWB_DSMMA/Lexi/lightning_logs/version_1/checkpoints/epoch=8-step=567.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lexington/anaconda3/envs/test_env/lib/python3.11/site-packages/swyft/lightning/utils.py:535: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(self.best_model_path)\n"
     ]
    }
   ],
   "source": [
    "trainer = swyft.SwyftTrainer(accelerator=DEVICE, precision=64)\n",
    "\n",
    "# Step 4: Prepare the data module for training\n",
    "dm = swyft.SwyftDataModule(samples, batch_size=128)\n",
    "\n",
    "# Step 5: Instantiate and train the network\n",
    "network = VAE()\n",
    "trainer.fit(network, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following callbacks returned in `LightningModule.configure_callbacks` will override existing callbacks passed to Trainer: EarlyStopping, ModelCheckpoint\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62cb45786a654695b94c9ba03edf3c7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 63it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lexington/anaconda3/envs/test_env/lib/python3.11/site-packages/pytorch_lightning/loops/epoch/prediction_epoch_loop.py:173: UserWarning: Lightning couldn't infer the indices fetched for your dataloader.\n",
      "  warning_cache.warn(\"Lightning couldn't infer the indices fetched for your dataloader.\")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (1024) must match the size of tensor b (2) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Create prior samples\u001b[39;00m\n\u001b[1;32m     13\u001b[0m prior_samples \u001b[38;5;241m=\u001b[39m swyft\u001b[38;5;241m.\u001b[39mSamples(z \u001b[38;5;241m=\u001b[39m z_alpha)\n\u001b[0;32m---> 14\u001b[0m predictions \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39minfer(network, obs, prior_samples)\n",
      "File \u001b[0;32m~/anaconda3/envs/test_env/lib/python3.11/site-packages/swyft/lightning/core.py:316\u001b[0m, in \u001b[0;36mSwyftTrainer.infer\u001b[0;34m(self, model, A, B, return_sample_ratios, batch_size)\u001b[0m\n\u001b[1;32m    314\u001b[0m     dl2 \u001b[38;5;241m=\u001b[39m B\n\u001b[1;32m    315\u001b[0m dl \u001b[38;5;241m=\u001b[39m CombinedLoader([dl1, dl2], mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_size_cycle\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 316\u001b[0m ratio_batches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(model, dl)\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_sample_ratios:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ratio_batches[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/test_env/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:892\u001b[0m, in \u001b[0;36mTrainer.predict\u001b[0;34m(self, model, dataloaders, datamodule, return_predictions, ckpt_path)\u001b[0m\n\u001b[1;32m    890\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_unwrap_optimized(model)\n\u001b[1;32m    891\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m_lightning_module \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m--> 892\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m call\u001b[38;5;241m.\u001b[39m_call_and_handle_interrupt(\n\u001b[1;32m    893\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_impl, model, dataloaders, datamodule, return_predictions, ckpt_path\n\u001b[1;32m    894\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/test_env/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:38\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 38\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     41\u001b[0m     trainer\u001b[38;5;241m.\u001b[39m_call_teardown_hook()\n",
      "File \u001b[0;32m~/anaconda3/envs/test_env/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:938\u001b[0m, in \u001b[0;36mTrainer._predict_impl\u001b[0;34m(self, model, dataloaders, datamodule, return_predictions, ckpt_path)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_set_ckpt_path(\n\u001b[1;32m    933\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn, ckpt_path, model_provided\u001b[38;5;241m=\u001b[39mmodel_provided, model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    934\u001b[0m )\n\u001b[1;32m    936\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predicted_ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt_path  \u001b[38;5;66;03m# TODO: remove in v1.8\u001b[39;00m\n\u001b[0;32m--> 938\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run(model, ckpt_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt_path)\n\u001b[1;32m    940\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredicting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/test_env/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:1112\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39mrestore_training_state()\n\u001b[1;32m   1110\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39mresume_end()\n\u001b[0;32m-> 1112\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_stage()\n\u001b[1;32m   1114\u001b[0m log\u001b[38;5;241m.\u001b[39mdetail(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_teardown()\n",
      "File \u001b[0;32m~/anaconda3/envs/test_env/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:1190\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_evaluate()\n\u001b[1;32m   1189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredicting:\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_predict()\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_train()\n",
      "File \u001b[0;32m~/anaconda3/envs/test_env/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:1244\u001b[0m, in \u001b[0;36mTrainer._run_predict\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1242\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_loop\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m   1243\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _evaluation_context(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_mode):\n\u001b[0;32m-> 1244\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_loop\u001b[38;5;241m.\u001b[39mrun()\n",
      "File \u001b[0;32m~/anaconda3/envs/test_env/lib/python3.11/site-packages/pytorch_lightning/loops/loop.py:199\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 199\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madvance(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/test_env/lib/python3.11/site-packages/pytorch_lightning/loops/dataloader/prediction_loop.py:100\u001b[0m, in \u001b[0;36mPredictionLoop.advance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28menumerate\u001b[39m(dataloader)\n\u001b[1;32m     98\u001b[0m dl_max_batches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_batches[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_dataloader_idx]\n\u001b[0;32m--> 100\u001b[0m dl_predictions, dl_batch_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch_loop\u001b[38;5;241m.\u001b[39mrun(\n\u001b[1;32m    101\u001b[0m     dataloader_iter, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_dataloader_idx, dl_max_batches, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_dataloaders\n\u001b[1;32m    102\u001b[0m )\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictions\u001b[38;5;241m.\u001b[39mappend(dl_predictions)\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch_batch_indices\u001b[38;5;241m.\u001b[39mappend(dl_batch_indices)\n",
      "File \u001b[0;32m~/anaconda3/envs/test_env/lib/python3.11/site-packages/pytorch_lightning/loops/loop.py:199\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 199\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madvance(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/test_env/lib/python3.11/site-packages/pytorch_lightning/loops/epoch/prediction_epoch_loop.py:100\u001b[0m, in \u001b[0;36mPredictionEpochLoop.advance\u001b[0;34m(self, dataloader_iter, dataloader_idx, dl_max_batches, num_dataloaders)\u001b[0m\n\u001b[1;32m     96\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39m_call_strategy_hook(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_to_device\u001b[39m\u001b[38;5;124m\"\u001b[39m, batch, dataloader_idx\u001b[38;5;241m=\u001b[39mdataloader_idx)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_ready()\n\u001b[0;32m--> 100\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_step(batch, batch_idx, dataloader_idx)\n",
      "File \u001b[0;32m~/anaconda3/envs/test_env/lib/python3.11/site-packages/pytorch_lightning/loops/epoch/prediction_epoch_loop.py:129\u001b[0m, in \u001b[0;36mPredictionEpochLoop._predict_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39m_call_lightning_module_hook(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_predict_batch_start\u001b[39m\u001b[38;5;124m\"\u001b[39m, batch, batch_idx, dataloader_idx)\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_started()\n\u001b[0;32m--> 129\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39m_call_strategy_hook(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39mstep_kwargs\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_processed()\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m predictions \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/test_env/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:1494\u001b[0m, in \u001b[0;36mTrainer._call_strategy_hook\u001b[0;34m(self, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1491\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1494\u001b[0m     output \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/anaconda3/envs/test_env/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py:408\u001b[0m, in \u001b[0;36mStrategy.predict_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39mpredict_step_context():\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, PredictStep)\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpredict_step(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/test_env/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/double.py:61\u001b[0m, in \u001b[0;36mLightningDoublePrecisionModule.predict_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m---> 61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule\u001b[38;5;241m.\u001b[39mpredict_step(\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;241m*\u001b[39mLightningDoublePrecisionModule\u001b[38;5;241m.\u001b[39m_move_float_tensors_to_double(args),\n\u001b[1;32m     63\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mLightningDoublePrecisionModule\u001b[38;5;241m.\u001b[39m_move_float_tensors_to_double(kwargs),\n\u001b[1;32m     64\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/test_env/lib/python3.11/site-packages/swyft/lightning/core.py:149\u001b[0m, in \u001b[0;36mLossAggregationSteps.predict_step\u001b[0;34m(self, batch, *args, **kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m A \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    148\u001b[0m B \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(A, B)\n",
      "File \u001b[0;32m~/anaconda3/envs/test_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/test_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[4], line 41\u001b[0m, in \u001b[0;36mVAE.forward\u001b[0;34m(self, A, B)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, A, B): \n\u001b[1;32m     40\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msummarizer(A[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogratios(s, B[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/test_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/test_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/test_env/lib/python3.11/site-packages/swyft/lightning/estimators.py:224\u001b[0m, in \u001b[0;36mLogRatioEstimator_1dim.forward\u001b[0;34m(self, x, z)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, z):\n\u001b[1;32m    223\u001b[0m     x, z \u001b[38;5;241m=\u001b[39m equalize_tensors(x, z)\n\u001b[0;32m--> 224\u001b[0m     zt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mptrans(z)\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m    225\u001b[0m     logratios \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(x, zt)\n\u001b[1;32m    226\u001b[0m     w \u001b[38;5;241m=\u001b[39m LogRatioSamples(\n\u001b[1;32m    227\u001b[0m         logratios, z\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvarnames, metadata\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMLP1d\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m    228\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/test_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/test_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/test_env/lib/python3.11/site-packages/swyft/networks/classifier.py:93\u001b[0m, in \u001b[0;36mParameterTransform.forward\u001b[0;34m(self, parameters)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, parameters: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m---> 93\u001b[0m     parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39monline_z_score(parameters)\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_marginal_block(parameters, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmarginal_indices)\n",
      "File \u001b[0;32m~/anaconda3/envs/test_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/test_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/test_env/lib/python3.11/site-packages/swyft/networks/standardization.py:63\u001b[0m, in \u001b[0;36mOnlineStandardizingLayer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mean, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_M2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parallel_algorithm(x)\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (x \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstd\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (1024) must match the size of tensor b (2) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "# Define priors\n",
    "omega_prior = stats.loguniform(1e-8, 1e-7)  # Log-uniform distribution for omega\n",
    "alpha_prior = stats.uniform(0, 1)            # Uniform distribution for alpha\n",
    "\n",
    "# Sample 1000 points from the priors\n",
    "z_omega = omega_prior.rvs(20000)\n",
    "z_alpha = alpha_prior.rvs(20000)\n",
    "\n",
    "z_samps = np.column_stack((z_omega, z_alpha))\n",
    "\n",
    "\n",
    "# Create prior samples\n",
    "prior_samples = swyft.Samples(z = z_samps)\n",
    "predictions = trainer.infer(network, obs, prior_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "ln_r = np.asarray(predictions[0].logratios)\n",
    "r_1 = np.exp(ln_r[:, 0])\n",
    "r_2 = np.exp(ln_r[:, 1])\n",
    "post_Omega = np.random.choice(z_samps[:, 0], size=1000, p = r_1/np.sum(r_1))\n",
    "post_alpha = np.random.choice(z_samps[:, 1], size=1000, p = r_2/np.sum(r_2))\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.subplot(131)\n",
    "sns.histplot(post_Omega, bins=30, element=\"step\", fill=False)\n",
    "plt.axvline(obs['z'][0], color=\"red\")\n",
    "plt.xlabel(r\"$\\log_{10}\\Omega_\\alpha$\")\n",
    "plt.subplot(132)\n",
    "sns.histplot(post_alpha, bins=30, element=\"step\", fill=False)\n",
    "plt.axvline(obs['z'][1], color=\"red\")\n",
    "plt.xlabel(r\"$\\alpha$\")\n",
    "plt.subplot(133)\n",
    "for i in range(500):\n",
    "    plt.loglog(sim.freq, 10**post_Omega[i] * (sim.freq/sim.fref)**post_alpha[i], alpha=0.2, color=\"gray\")\n",
    "plt.xlabel(r\"$f$/Hz\")\n",
    "plt.ylabel(r\"$\\Omega(f)$\")\n",
    "plt.subplots_adjust(wspace=0.5)\n",
    "plt.loglog(sim.freq, 10**obs['z'][0]*(sim.freq/sim.fref)**obs['z'][1], color=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
