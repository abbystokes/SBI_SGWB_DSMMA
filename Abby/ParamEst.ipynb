{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# Install Packages\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pylab as plt\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import swyft\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n",
    "import scipy\n",
    "import time\n",
    "plt.rc(\"text\", usetex=True)\n",
    "plt.rc(\"font\", family=\"Serif\")\n",
    "DEVICE = 'gpu' if torch.cuda.is_available() else 'cpu'\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define simulator parameters\n",
    "freq = np.arange(5.00,1024,1/4)\n",
    "pi = np.pi\n",
    "sqrt = np.sqrt\n",
    "H100 = 3.241e-18\n",
    "h    = 0.679\n",
    "H0   = h * H100\n",
    "\n",
    "# Define Simulator\n",
    "class Simulator(swyft.Simulator):\n",
    "    def __init__(self, fref, psd, gamma, T_obs, Nbins=4076, bounds=None):\n",
    "        super().__init__()\n",
    "        self.fref      = fref\n",
    "        self.psd       = psd\n",
    "        self.gamma     = gamma\n",
    "        self.T_obs     = T_obs\n",
    "        \n",
    "        self.transform_samples = swyft.to_numpy32\n",
    "        self.Nbins = Nbins\n",
    "        self.freq = np.linspace(5., 1024 + (1024-5)/Nbins , Nbins)\n",
    "        self.sample_z = swyft.RectBoundSampler([stats.loguniform(1e-8,1e-7), #alpha\n",
    "                                                stats.uniform(0,3)], #omega alpha\n",
    "                                                bounds = bounds) #bounds changes range of the prior\n",
    "\n",
    "    def psd_interp(self):\n",
    "        return scipy.interpolate.interp1d(self.psd[:,0], self.psd[:,1])(self.freq)\n",
    "    \n",
    "    def gamma_interp(self):\n",
    "        return scipy.interpolate.interp1d(self.gamma[:, 0], self.gamma[:, 1])(self.freq)\n",
    "    \n",
    "    def sigma(self):\n",
    "        numerator = (20*pi**2*self.freq**3)**2 * self.psd_interp()**2\n",
    "        denomenator = (3*H0**2)**2 * 8*self.gamma_interp()**2\n",
    "        T = 1/(self.freq[1]-self.freq[0])\n",
    "        N = 2*self.T_obs // T - 1\n",
    "        return np.sqrt(numerator/denomenator/N)\n",
    "    \n",
    "    def C_groundtruth(self, z):\n",
    "        Omega_ref = z[0]\n",
    "        alpha     = z[1]\n",
    "        C_hat_ij = Omega_ref * (self.freq/self.fref)**alpha\n",
    "        return C_hat_ij\n",
    "    \n",
    "    def build(self, graph):\n",
    "        z = graph.node('z', self.sample_z)\n",
    "        m = graph.node('m', self.C_groundtruth, z)\n",
    "        x = graph.node(\"x\", lambda m: m + np.random.normal(0, self.sigma()), m) #Ground truth wih sigma noise\n",
    "        sigma = graph.node('sigma',self.sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:07<00:00, 1398.11it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2a4ace0d0>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sample from Simulator\n",
    "\n",
    "n_samples = 1000\n",
    "fref = 25\n",
    "CE_PSD = np.genfromtxt(\"data/cosmic_explorer_40km_for_paper.txt\")\n",
    "CE_PSD[0, 0]  = 4.99999999999999999\n",
    "CE_PSD[:, 1] = CE_PSD[:, 1]**2\n",
    "gamma_HL = np.genfromtxt(\"data/gamma_HL.txt\")\n",
    "T_obs = 365 * 24 * 3600\n",
    "\n",
    "sim = Simulator(fref, CE_PSD, gamma_HL, T_obs, bounds=None)\n",
    "\n",
    "obs = sim.sample(conditions = {'z': np.array([5e-8, 2.1])})\n",
    "samples = sim.sample(N = 10000)\n",
    "\n",
    "plt.loglog(sim.freq, obs['x'], 'r', lw=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(swyft.SwyftModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Log-ratio estimator with 1 feature (x) and 2 parameters (alpha, omega)\n",
    "        self.logratios = swyft.LogRatioEstimator_1dim(\n",
    "            num_features=1,  # Number of features in x (simulated observation)\n",
    "            num_params=2,    # Two parameters to infer: alpha and omega\n",
    "            varnames=['omega', 'alpha'],  # Names of the parameters\n",
    "            num_blocks=4     # Number of neural network blocks\n",
    "        )\n",
    "\n",
    "    def forward(self, A, B):\n",
    "        return self.logratios(A['x'], B['m'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/setup.py:187: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pytorch_lightning/loops/utilities.py:73: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "The following callbacks returned in `LightningModule.configure_callbacks` will override existing callbacks passed to Trainer: ModelCheckpoint\n",
      "\n",
      "  | Name      | Type                   | Params\n",
      "-----------------------------------------------------\n",
      "0 | logratios | LogRatioEstimator_1dim | 69.1 K\n",
      "-----------------------------------------------------\n",
      "69.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "69.1 K    Total params\n",
      "0.276     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected size for first two dimensions of batch2 tensor to be: [512, 2] but got: [512, 4077].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Step 5: Instantiate and train the network\u001b[39;00m\n\u001b[1;32m      7\u001b[0m network \u001b[38;5;241m=\u001b[39m Network()\n\u001b[0;32m----> 8\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdm\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:544\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 544\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:580\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    574\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    576\u001b[0m     ckpt_path,\n\u001b[1;32m    577\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    578\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    579\u001b[0m )\n\u001b[0;32m--> 580\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:987\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    982\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    984\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    986\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 987\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    989\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    990\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    991\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    992\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:1031\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[1;32m   1030\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m-> 1031\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_sanity_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1032\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[1;32m   1033\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_loop\u001b[38;5;241m.\u001b[39mrun()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:1060\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1057\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;66;03m# run eval step\u001b[39;00m\n\u001b[0;32m-> 1060\u001b[0m \u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1062\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1064\u001b[0m \u001b[38;5;66;03m# reset logger connector\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pytorch_lightning/loops/utilities.py:182\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m     context_manager \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mno_grad\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pytorch_lightning/loops/evaluation_loop.py:135\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mis_last_batch \u001b[38;5;241m=\u001b[39m data_fetcher\u001b[38;5;241m.\u001b[39mdone\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;66;03m# run step hooks\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;66;03m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pytorch_lightning/loops/evaluation_loop.py:396\u001b[0m, in \u001b[0;36m_EvaluationLoop._evaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx, dataloader_iter)\u001b[0m\n\u001b[1;32m    390\u001b[0m hook_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_step\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mtesting \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    391\u001b[0m step_args \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_step_args_from_hook_kwargs(hook_kwargs, hook_name)\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_dataloader_iter\n\u001b[1;32m    394\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m (dataloader_iter,)\n\u001b[1;32m    395\u001b[0m )\n\u001b[0;32m--> 396\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstep_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_processed()\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_dataloader_iter:\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;66;03m# update the hook kwargs now that the step method might have consumed the iterator\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:309\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 309\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    312\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py:412\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module:\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_redirection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 412\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/swyft/lightning/core.py:137\u001b[0m, in \u001b[0;36mLossAggregationSteps.validation_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidation_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, batch_idx):\n\u001b[0;32m--> 137\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_calc_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, loss, prog_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, on_step\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, on_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/swyft/lightning/core.py:107\u001b[0m, in \u001b[0;36mLossAggregationSteps._calc_loss\u001b[0;34m(self, batch, randomized)\u001b[0m\n\u001b[1;32m    104\u001b[0m num_pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mlist\u001b[39m(x\u001b[38;5;241m.\u001b[39mvalues())[\u001b[38;5;241m0\u001b[39m])  \u001b[38;5;66;03m# Number of positive examples\u001b[39;00m\n\u001b[1;32m    105\u001b[0m num_neg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mlist\u001b[39m(z\u001b[38;5;241m.\u001b[39mvalues())[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m-\u001b[39m num_pos  \u001b[38;5;66;03m# Number of negative examples\u001b[39;00m\n\u001b[0;32m--> 107\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Evaluate network\u001b[39;00m\n\u001b[1;32m    108\u001b[0m loss_tot \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    110\u001b[0m logratios \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logratios(\n\u001b[1;32m    111\u001b[0m     out\n\u001b[1;32m    112\u001b[0m )  \u001b[38;5;66;03m# Generates concatenated flattened list of all estimated log ratios\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[14], line 13\u001b[0m, in \u001b[0;36mNetwork.forward\u001b[0;34m(self, A, B)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, A, B):\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogratios\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mz\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/swyft/lightning/estimators.py:225\u001b[0m, in \u001b[0;36mLogRatioEstimator_1dim.forward\u001b[0;34m(self, x, z)\u001b[0m\n\u001b[1;32m    223\u001b[0m x, z \u001b[38;5;241m=\u001b[39m equalize_tensors(x, z)\n\u001b[1;32m    224\u001b[0m zt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mptrans(z)\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[0;32m--> 225\u001b[0m logratios \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m w \u001b[38;5;241m=\u001b[39m LogRatioSamples(\n\u001b[1;32m    227\u001b[0m     logratios, z\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvarnames, metadata\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMLP1d\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m    228\u001b[0m )\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m w\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/swyft/networks/classifier.py:179\u001b[0m, in \u001b[0;36mMarginalClassifier.forward\u001b[0;34m(self, features, marginal_block)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLmax \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    178\u001b[0m     combined \u001b[38;5;241m=\u001b[39m spectral_embedding(combined, Lmax\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLmax)\n\u001b[0;32m--> 179\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombined\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/swyft/networks/channelized.py:133\u001b[0m, in \u001b[0;36mResidualNetWithChannel.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 133\u001b[0m     temps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitial_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[1;32m    135\u001b[0m         temps \u001b[38;5;241m=\u001b[39m block(temps)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/swyft/networks/channelized.py:28\u001b[0m, in \u001b[0;36mLinearWithChannel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequires (..., channel, features) shape.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     27\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 28\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected size for first two dimensions of batch2 tensor to be: [512, 2] but got: [512, 4077]."
     ]
    }
   ],
   "source": [
    "trainer = swyft.SwyftTrainer(accelerator=DEVICE, precision=64)\n",
    "\n",
    "# Step 4: Prepare the data module for training\n",
    "dm = swyft.SwyftDataModule(samples, batch_size=128)\n",
    "\n",
    "# Step 5: Instantiate and train the network\n",
    "network = Network()\n",
    "trainer.fit(network, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define swyft module\n",
    "\n",
    "class Network(swyft.SwyftModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embedding = torch.nn.Linear(10, 2)\n",
    "        self.logratios1 = swyft.LogRatioEstimator_1dim(num_features = 2, num_params = 2, varnames = 'z')\n",
    "        self.logratios2 = swyft.LogRatioEstimator_Ndim(num_features = 2, marginals = ((0, 1),), varnames = 'z')\n",
    "\n",
    "    def forward(self, A, B):\n",
    "        embedding = self.embedding(A['x'])\n",
    "        logratios1 = self.logratios1(embedding, B['z'])\n",
    "        logratios2 = self.logratios2(embedding, B['z'])\n",
    "        return logratios1, logratios2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/setup.py:187: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "trainer = swyft.SwyftTrainer(accelerator = DEVICE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = swyft.SwyftDataModule(samples, batch_size = 64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pytorch_lightning/loops/utilities.py:73: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "The following callbacks returned in `LightningModule.configure_callbacks` will override existing callbacks passed to Trainer: ModelCheckpoint\n",
      "\n",
      "  | Name       | Type                   | Params\n",
      "------------------------------------------------------\n",
      "0 | embedding  | Linear                 | 22    \n",
      "1 | logratios1 | LogRatioEstimator_1dim | 34.9 K\n",
      "2 | logratios2 | LogRatioEstimator_Ndim | 17.5 K\n",
      "------------------------------------------------------\n",
      "52.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "52.5 K    Total params\n",
      "0.210     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (64x4076 and 10x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m network \u001b[38;5;241m=\u001b[39m Network()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdm\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:544\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 544\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:580\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    574\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    576\u001b[0m     ckpt_path,\n\u001b[1;32m    577\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    578\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    579\u001b[0m )\n\u001b[0;32m--> 580\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:987\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    982\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    984\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    986\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 987\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    989\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    990\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    991\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    992\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:1031\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[1;32m   1030\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m-> 1031\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_sanity_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1032\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[1;32m   1033\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_loop\u001b[38;5;241m.\u001b[39mrun()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:1060\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1057\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;66;03m# run eval step\u001b[39;00m\n\u001b[0;32m-> 1060\u001b[0m \u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1062\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1064\u001b[0m \u001b[38;5;66;03m# reset logger connector\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pytorch_lightning/loops/utilities.py:182\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m     context_manager \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mno_grad\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pytorch_lightning/loops/evaluation_loop.py:135\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mis_last_batch \u001b[38;5;241m=\u001b[39m data_fetcher\u001b[38;5;241m.\u001b[39mdone\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;66;03m# run step hooks\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;66;03m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pytorch_lightning/loops/evaluation_loop.py:396\u001b[0m, in \u001b[0;36m_EvaluationLoop._evaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx, dataloader_iter)\u001b[0m\n\u001b[1;32m    390\u001b[0m hook_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_step\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mtesting \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    391\u001b[0m step_args \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_step_args_from_hook_kwargs(hook_kwargs, hook_name)\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_dataloader_iter\n\u001b[1;32m    394\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m (dataloader_iter,)\n\u001b[1;32m    395\u001b[0m )\n\u001b[0;32m--> 396\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstep_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_processed()\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_dataloader_iter:\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;66;03m# update the hook kwargs now that the step method might have consumed the iterator\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:309\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 309\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    312\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py:412\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module:\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_redirection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 412\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/swyft/lightning/core.py:137\u001b[0m, in \u001b[0;36mLossAggregationSteps.validation_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidation_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, batch_idx):\n\u001b[0;32m--> 137\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_calc_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, loss, prog_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, on_step\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, on_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/swyft/lightning/core.py:107\u001b[0m, in \u001b[0;36mLossAggregationSteps._calc_loss\u001b[0;34m(self, batch, randomized)\u001b[0m\n\u001b[1;32m    104\u001b[0m num_pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mlist\u001b[39m(x\u001b[38;5;241m.\u001b[39mvalues())[\u001b[38;5;241m0\u001b[39m])  \u001b[38;5;66;03m# Number of positive examples\u001b[39;00m\n\u001b[1;32m    105\u001b[0m num_neg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mlist\u001b[39m(z\u001b[38;5;241m.\u001b[39mvalues())[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m-\u001b[39m num_pos  \u001b[38;5;66;03m# Number of negative examples\u001b[39;00m\n\u001b[0;32m--> 107\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Evaluate network\u001b[39;00m\n\u001b[1;32m    108\u001b[0m loss_tot \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    110\u001b[0m logratios \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logratios(\n\u001b[1;32m    111\u001b[0m     out\n\u001b[1;32m    112\u001b[0m )  \u001b[38;5;66;03m# Generates concatenated flattened list of all estimated log ratios\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[9], line 11\u001b[0m, in \u001b[0;36mNetwork.forward\u001b[0;34m(self, A, B)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, A, B):\n\u001b[0;32m---> 11\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     logratios1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogratios1(embedding, B[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     13\u001b[0m     logratios2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogratios2(embedding, B[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (64x4076 and 10x2)"
     ]
    }
   ],
   "source": [
    "network = Network()\n",
    "trainer.fit(network, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
